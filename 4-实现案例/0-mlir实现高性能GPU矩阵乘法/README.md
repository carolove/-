# mlir 实现高性能GPU矩阵乘法
- 目标就是实现[MLIR 编译器基础设施生成高效的 GPU 代码](https://arxiv.org/pdf/2108.13191)

## 涉及的知识点，对于初学者的我来说，主要涉及的知识点包括
- [c++ 环境以及cmake build 构建体系](https://github.com/carolove/Study-with-Machine-Learning/blob/main/4-%E5%AE%9E%E7%8E%B0%E6%A1%88%E4%BE%8B/0-mlir%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BDGPU%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/00-c%2B%2B%20%E7%8E%AF%E5%A2%83%E4%BB%A5%E5%8F%8Acmake%20build%20%E6%9E%84%E5%BB%BA%E4%BD%93%E7%B3%BB.md)
- [llvm/mlir构建新项目的目录组织结构](https://github.com/carolove/Study-with-Machine-Learning/blob/main/4-%E5%AE%9E%E7%8E%B0%E6%A1%88%E4%BE%8B/0-mlir%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BDGPU%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/01-llvm-mlir%E6%9E%84%E5%BB%BA%E6%96%B0%E9%A1%B9%E7%9B%AE%E7%9A%84%E7%9B%AE%E5%BD%95%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84.md)
- [mlir现已存在dialect体系](https://github.com/carolove/Study-with-Machine-Learning/blob/main/4-%E5%AE%9E%E7%8E%B0%E6%A1%88%E4%BE%8B/0-mlir%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BDGPU%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/02-mlir%E7%8E%B0%E5%B7%B2%E5%AD%98%E5%9C%A8dialect%E4%BD%93%E7%B3%BB.md)
- [加入自定义dialect、自定义pass pipeline、自定义rewrite pattern的原则、代码组织结构](https://github.com/carolove/Study-with-Machine-Learning/blob/main/4-%E5%AE%9E%E7%8E%B0%E6%A1%88%E4%BE%8B/0-mlir%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BDGPU%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/03-%E5%8A%A0%E5%85%A5%E8%87%AA%E5%AE%9A%E4%B9%89dialect%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89pass%20pipeline%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89rewrite%20pattern%E7%9A%84%E5%8E%9F%E5%88%99%E3%80%81%E4%BB%A3%E7%A0%81%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84.md)
- [矩阵乘法优化的通用优化策略，比如多面体变形、循环展开](https://github.com/carolove/Study-with-Machine-Learning/blob/main/4-%E5%AE%9E%E7%8E%B0%E6%A1%88%E4%BE%8B/0-mlir%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BDGPU%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/04-%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E4%BC%98%E5%8C%96%E7%9A%84%E9%80%9A%E7%94%A8%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5%EF%BC%8C%E6%AF%94%E5%A6%82%E5%A4%9A%E9%9D%A2%E4%BD%93%E5%8F%98%E5%BD%A2%E3%80%81%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80.md)
- [在gpu硬件结构层，矩阵乘法涉及的优化策略，比如共享缓存、寄存器缓存、调度流水线](https://github.com/carolove/Study-with-Machine-Learning/blob/main/4-%E5%AE%9E%E7%8E%B0%E6%A1%88%E4%BE%8B/0-mlir%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BDGPU%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/05-%E5%9C%A8gpu%E7%A1%AC%E4%BB%B6%E7%BB%93%E6%9E%84%E5%B1%82%EF%BC%8C%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E6%B6%89%E5%8F%8A%E7%9A%84%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5%EF%BC%8C%E6%AF%94%E5%A6%82%E5%85%B1%E4%BA%AB%E7%BC%93%E5%AD%98%E3%80%81%E5%AF%84%E5%AD%98%E5%99%A8%E7%BC%93%E5%AD%98%E3%80%81%E8%B0%83%E5%BA%A6%E6%B5%81%E6%B0%B4%E7%BA%BF.md)

## 论文解读
- 论文提出，现在市面上在研究GEMM相关优化的工作，主要有这么几个方向，1、开发手工私库支撑比如julia语言API库；2、基于多面体代码生成；3、基于triton编译器；4、基于mlir IR基础设施，本论文是第四种，基于mlir IR基础设施来做高性能代码生成的
- 相关工作源码层被提交合并到LLVM/MLIR WMMA 相关提案中了
- mlir相关的几个dialect：**affine dialect**-多面体编译技术，使依赖分析、循环转换高校可靠；**GPU dialect**-类似于CUDA/OpenCL的通用GPU编程范式，提供与供应商无关的抽象来模拟GPU特定的操作和属性；**nvvm dialect**-提供了直接映射到llvm nvptx后端的操作；**llvm dialect**-mlir中最低级别的抽象；
