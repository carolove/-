# 论文探究
## 顶层linalg.matmul表达
```
// mlir-opt matmul-gpu.mlir -convert-linalg-to-affine-loops -o affine-gpu.mlir
module {
    func.func @matmul_linalg(%A: memref<64x32xf32>, %B: memref<32x64xf32>, %C: memref<64x64xf32>) {
        linalg.matmul ins(%A, %B : memref<64x32xf32>, memref<32x64xf32>)
            outs(%C: memref<64x64xf32>)
        return
    }
}

```
## 实现论文的affine pipeline的2-level loop tiling
- linalg.matmul 变换为affine的操作: mlir-opt matmul-gpu.mlir -convert-linalg-to-affine-loops -o affine-gpu.mlir
- 相关的学习是来自llvm-project/mlir/test/Dialect/Linalg/affine.mlir有详细的关于linalg到affine的测试案例
```
module {
  func.func @matmul_linalg(%arg0: memref<64x32xf32>, %arg1: memref<32x64xf32>, %arg2: memref<64x64xf32>) {
    affine.for %arg3 = 0 to 64 {
      affine.for %arg4 = 0 to 64 {
        affine.for %arg5 = 0 to 32 {
          %0 = affine.load %arg0[%arg3, %arg5] : memref<64x32xf32>
          %1 = affine.load %arg1[%arg5, %arg4] : memref<32x64xf32>
          %2 = affine.load %arg2[%arg3, %arg4] : memref<64x64xf32>
          %3 = arith.mulf %0, %1 : f32
          %4 = arith.addf %2, %3 : f32
          affine.store %4, %arg2[%arg3, %arg4] : memref<64x64xf32>
        }
      }
    }
    return
  }
}
```

## tiling
- 总计9层affine.for
- 最外层的，affine.for %i = 0 to 8192 step 128; affine.for %j = 0 to 8192 step 128; 是对应的线程块 block的划分，划分完以后A 加载 8192 * 128；B加载128 * 8192；
- 第三个affine.for %k = 0 to 8192 step 64；是SM的划分，也是shared memory的划分， 划分完以后A 加载 64 * 128；B加载128 * 64；加载进入shared memory
- 第四、第五，ii 0 to 128 step 64、jj 0 to 128 step 32 的循环，是对wrap的划分， 划分完以后A 加载 64 * 62；B加载32 * 64，一个sm有 8个wrap
- 第六个affine.for, kk层是核心计算层，kk 0 to 64 step 32,
- 最里层的三层for循环，是wrap计算，进一步划分为wvvm操作需要的寄存器存储大小，将c直接加载道寄存器内

## wvvm操作
- 加入了gpu.subgroup_mma_compute/gpu.subgroup_mma_load_matrix/gpu.subgroup_mma_store_matrix操作
- 
