{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 时隔大半年重新学习异构编译相关，一开始学习GPU cuda 矩阵乘法优化、llmv/mlir到最终确定学习triton作为两条学习路线的结合点\n",
    "- 6月-12月和小伙伴研发算力云并上线，尽管没有继续钻研底层异构编译，但是在上层比如大模型框架在算力中心的落地、在上层以及应用层理解transformer算法、具体的训练脚本比如transformers Trainer 或者accelerate训练框架脚本在算力中心的落地等，在应用层、上层系统对整体也有了了解\n",
    "- 再次重新捡回来学习异构编译，应该是有更明确的目标，一方面的目标是要学懂以前浮于表面的triton kernel的开发，另一方面是要在triton的实现pr上面有所贡献；这样在应用层学会triton来实现原来需要用cuda实现的顶层软件框架比如accelerate所需要的算子，也可以在triton原理上，特别是mlir生态有更进一步的理解\n",
    "- 这方面的工作需求，特别是开发工作会不会停滞，随着算子的越来越丰富，异构设备支持越来越完善会不会出现停滞，这个我认为的人工智能路线应该不会轻易地停滞\n",
    "- 我认为的人工智能未来应该是服务于人类智力平权，现在的人群中，因为知识的复杂度还是超过了大部分的能力，导致很多人其实是没办法有效的学习、组织现有的知识，表现就是很多差生学不懂，但是随着人工智能的发展，会缩小所谓的差生和优等生在智力、思维思考能力的差距，实现智力平权\n",
    "- 通过这来看的话，未来模型的训练可能不会是无限扩张的，参数量会固化在一定的区间，这样未来的异构设备的主战场就是推理芯片，按照现在的设备目标，40G显存、80tflops算力是总需求，功耗才是未来设备迭代的目标，会有不同的异构设备的推出，因此可能是持续迭代 异构编译体系的，有一点类似于以前的嵌入式BSP工程师、驱动工程师"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sglang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
