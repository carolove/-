{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.1105e-04, 9.9909e-01],\n",
      "        [1.0000e+00, 9.6027e-24]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def native_softmax(x):\n",
    "    x_max = x.max(dim=1)[0]\n",
    "\n",
    "    z = x - x_max[:,None]\n",
    "\n",
    "    e = torch.exp(z)\n",
    "    sum = e.sum(dim=1)\n",
    "\n",
    "    return e/sum[:,None]\n",
    "\n",
    "\n",
    "x = torch.Tensor([[2,9],[54,1]])\n",
    "print(native_softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "# 这里的row_idx = tl.program_id(axis=0)表示当前程序的ID，而row_step = tl.num_programs(0)则表示总的程序数量。\n",
    "# 比如说，如果你有一个1000行的矩阵，而GPU上启动了100个并行程序，那么：\n",
    "# tl.num_programs(0) 返回100\n",
    "# 每个程序需要处理10行数据(1000/100)\n",
    "# 每个程序通过其program_id来确定它应该处理哪些行\n",
    "# 这种设计的优点是：\n",
    "# 实现了数据的并行处理\n",
    "# 确保了工作负载的均匀分配\n",
    "# 避免了线程之间的数据竞争\n",
    "# 在实际应用中，这个值通常用于：\n",
    "# 计算每个线程需要处理的数据量\n",
    "# 确定数据的步进(stride)大小\n",
    "# 实现负载均衡\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
